# ğŸ“Š Customer Satisfaction Analytics

> **AnÃ¡lisis avanzado de satisfacciÃ³n del cliente bancario con arquitectura moderna en AWS**

Un proyecto integral para centralizar, procesar y analizar datos de atenciÃ³n al cliente utilizando tÃ©cnicas de Big Data, Machine Learning y arquitectura de Data Lakehouse en AWS.

## ğŸ¯ Objetivos del Proyecto

- **Centralizar** datos de atenciÃ³n al cliente (tickets, encuestas NPS, reviews, transcripciones)
- **Analizar** mÃ©tricas de satisfacciÃ³n y detectar causas de insatisfacciÃ³n
- **Predecir** la satisfacciÃ³n del cliente usando modelos de Machine Learning
- **Visualizar** insights a travÃ©s de dashboards interactivos
- **Automatizar** el procesamiento y anÃ¡lisis de datos

## ğŸ—ï¸ Arquitectura

### Arquitectura de Data Lakehouse en AWS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   Data Lakehouse â”‚    â”‚   Consumption   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Simulador     â”‚ â”€â”€â–¶â”‚ Raw Data (S3)    â”‚ â”€â”€â–¶â”‚ AWS Athena      â”‚
â”‚ â€¢ APIs          â”‚    â”‚ Processed (S3)   â”‚    â”‚ QuickSight      â”‚
â”‚ â€¢ Kaggle        â”‚    â”‚ Curated (S3)     â”‚    â”‚ ML Models       â”‚
â”‚ â€¢ CFPB          â”‚    â”‚                  â”‚    â”‚ Notebooks       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   AWS Glue       â”‚
                      â”‚ â€¢ Data Catalog   â”‚
                      â”‚ â€¢ ETL Jobs       â”‚
                      â”‚ â€¢ Crawlers       â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principales

- **ğŸ—‚ï¸ Data Lake**: Amazon S3 con estructura lakehouse (raw/processed/curated)
- **ğŸ”„ ETL**: AWS Glue para transformaciones y PySpark jobs
- **ğŸ“Š CatalogaciÃ³n**: AWS Glue Data Catalog para metadatos
- **ğŸ” Consultas**: AWS Athena para anÃ¡lisis SQL ad-hoc
- **ğŸ“ˆ VisualizaciÃ³n**: Amazon QuickSight para dashboards
- **ğŸ§  ML**: Modelos de satisfacciÃ³n y anÃ¡lisis de sentimientos
- **ğŸ—ï¸ IaC**: Terraform para infraestructura como cÃ³digo

## ğŸ“ Estructura del Proyecto

```
customer-satisfaction-analytics/
â”œâ”€â”€ ğŸ“„ README.md                      # DocumentaciÃ³n principal
â”œâ”€â”€ ğŸ“‹ requirements.txt               # Dependencias Python
â”œâ”€â”€ ğŸ“Š data/                          # Datos del proyecto
â”‚   â”œâ”€â”€ ğŸ—‚ï¸ raw/                      # Datos originales
â”‚   â”œâ”€â”€ ğŸ”„ simulated/                # Datos sintÃ©ticos generados
â”‚   â”œâ”€â”€ âœ¨ processed/                # Datos limpiados
â”‚   â””â”€â”€ ğŸŒ external/                 # Datos de APIs externas
â”œâ”€â”€ ğŸ“¥ ingestion/                     # Pipeline de ingesta
â”‚   â”œâ”€â”€ ğŸ scripts/                  # Scripts Python
â”‚   â”œâ”€â”€ âš™ï¸ aws_glue_jobs/            # Jobs de AWS Glue
â”‚   â””â”€â”€ ğŸ“‹ configs/                  # Configuraciones
â”œâ”€â”€ ğŸ’¾ storage/                       # ConfiguraciÃ³n de almacenamiento
â”‚   â”œâ”€â”€ ğŸ  lakehouse/                # Definiciones lakehouse
â”‚   â”œâ”€â”€ ğŸ“¦ parquet_samples/          # Ejemplos Parquet
â”‚   â””â”€â”€ ğŸ“š metadata_catalog/         # CatÃ¡logo de metadatos
â”œâ”€â”€ âš™ï¸ processing/                    # TransformaciÃ³n de datos
â”‚   â”œâ”€â”€ âš¡ pyspark_jobs/             # Jobs PySpark
â”‚   â”œâ”€â”€ ğŸ—„ï¸ sql_transformations/      # Transformaciones SQL
â”‚   â””â”€â”€ ğŸ““ notebooks/                # Jupyter Notebooks
â”œâ”€â”€ ğŸ›¡ï¸ governance/                    # Gobernanza y seguridad
â”‚   â”œâ”€â”€ ğŸ”’ security_policies/        # PolÃ­ticas IAM
â”‚   â”œâ”€â”€ ğŸ“‹ lineage/                  # Linaje de datos
â”‚   â””â”€â”€ ğŸ” anonymization/            # Scripts anonimizaciÃ³n
â”œâ”€â”€ ğŸ“Š analytics/                     # AnÃ¡lisis y visualizaciÃ³n
â”‚   â”œâ”€â”€ ğŸ“ˆ bi_reports/               # Dashboards BI
â”‚   â”œâ”€â”€ ğŸ§  nlp_models/               # Modelos NLP
â”‚   â””â”€â”€ ğŸ”¬ exploratory/              # AnÃ¡lisis exploratorio
â”œâ”€â”€ ğŸ—ï¸ infra/                        # Infraestructura como cÃ³digo
â”‚   â”œâ”€â”€ ğŸŒ terraform/                # Scripts Terraform
â”‚   â””â”€â”€ â˜ï¸ cdk/                      # AWS CDK (opcional)
â”œâ”€â”€ ğŸ§ª tests/                        # Pruebas
â”‚   â”œâ”€â”€ ğŸ“¥ ingestion_tests/          # Tests de ingesta
â”‚   â”œâ”€â”€ âš™ï¸ processing_tests/         # Tests de procesamiento
â”‚   â””â”€â”€ ğŸ”— integration_tests/        # Tests de integraciÃ³n
â”œâ”€â”€ ğŸ“š docs/                         # DocumentaciÃ³n
â””â”€â”€ ğŸš€ .github/workflows/            # CI/CD con GitHub Actions
```

## ğŸš€ Inicio RÃ¡pido

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/customer-satisfaction-analytics.git
cd customer-satisfaction-analytics
```

### 2. Configurar Entorno Python

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### 3. Configurar AWS

```bash
# Configurar credenciales AWS
aws configure

# O usar variables de entorno
export AWS_ACCESS_KEY_ID=tu_access_key
export AWS_SECRET_ACCESS_KEY=tu_secret_key
export AWS_DEFAULT_REGION=us-east-1
```

### 4. Generar Datos SintÃ©ticos

```bash
# Generar datos de prueba
python ingestion/scripts/data_simulator.py \
    --tickets 10000 \
    --nps 5000 \
    --reviews 3000 \
    --transcripts 1000 \
    --output data/simulated
```

### 5. Desplegar Infraestructura

```bash
cd infra/terraform

# Inicializar Terraform
terraform init

# Planificar deployment
terraform plan -var="environment=dev"

# Aplicar cambios
terraform apply -var="environment=dev"
```

### 6. Subir Datos al Data Lake

```bash
# Subir datos simulados a S3
python ingestion/scripts/s3_uploader.py \
    --bucket tu-bucket-name \
    --data-dir data/simulated \
    --setup-structure \
    --create-glue-tables
```

## ğŸ“Š Datasets Incluidos

### 1. Customer Tickets (`customer_tickets`)
- **DescripciÃ³n**: Tickets de atenciÃ³n al cliente
- **Registros**: ~10,000
- **Campos clave**: `ticket_id`, `cliente_id`, `canal`, `satisfaccion_score`, `duracion_minutos`

### 2. NPS Surveys (`nps_surveys`)
- **DescripciÃ³n**: Encuestas Net Promoter Score
- **Registros**: ~5,000
- **Campos clave**: `nps_score`, `categoria_nps`, `comentario`

### 3. Customer Reviews (`customer_reviews`)
- **DescripciÃ³n**: Reviews online de clientes
- **Registros**: ~3,000
- **Campos clave**: `calificacion`, `texto_review`, `plataforma`

### 4. Conversation Transcripts (`conversation_transcripts`)
- **DescripciÃ³n**: Transcripciones de conversaciones
- **Registros**: ~1,000
- **Campos clave**: `transcript_texto`, `sentiment_score`, `satisfaccion_estimada`

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

```bash
# AWS Configuration
export AWS_REGION=us-east-1
export DATA_BUCKET=customer-satisfaction-data-lake
export GLUE_DATABASE=customer_satisfaction_db

# Processing Configuration
export SPARK_WORKERS=2
export GLUE_WORKER_TYPE=G.1X
```

### Archivos de ConfiguraciÃ³n

- `infra/terraform/variables.tf`: Variables de infraestructura
- `ingestion/configs/`: Configuraciones de ingesta
- `processing/configs/`: Configuraciones de procesamiento

## ğŸ“ˆ AnÃ¡lisis y MÃ©tricas

### KPIs Principales

- **ğŸ“Š SatisfacciÃ³n Promedio**: Score promedio por canal/perÃ­odo
- **ğŸ“ˆ NPS Score**: Net Promoter Score calculado
- **â±ï¸ Tiempo de ResoluciÃ³n**: DuraciÃ³n promedio por tipo de consulta
- **ğŸ“± DistribuciÃ³n por Canal**: Volumen y satisfacciÃ³n por canal
- **ğŸ¯ Tasa de ResoluciÃ³n**: % de tickets resueltos satisfactoriamente

### Consultas SQL Ejemplo

```sql
-- SatisfacciÃ³n promedio por canal
SELECT 
    canal,
    AVG(satisfaccion_score) as satisfaccion_promedio,
    COUNT(*) as total_tickets
FROM customer_tickets_processed 
WHERE year = 2024
GROUP BY canal;

-- EvoluciÃ³n del NPS mensual
SELECT 
    year,
    month,
    AVG(nps_score_calculado) as nps_mensual
FROM satisfaction_metrics
GROUP BY year, month
ORDER BY year, month;
```

## ğŸ§  Machine Learning

### Modelos Implementados

1. **ğŸ”® PredicciÃ³n de SatisfacciÃ³n**
   - Algoritmo: XGBoost, Random Forest
   - Features: Canal, duraciÃ³n, tipo consulta, historial cliente
   - MÃ©trica: AUC-ROC > 0.85

2. **ğŸ“ AnÃ¡lisis de Sentimientos**
   - TÃ©cnica: VADER, TextBlob, Transformers
   - Aplicado a: Reviews, comentarios NPS, transcripciones
   - Output: Score de sentimiento [-1, 1]

3. **ğŸ·ï¸ CategorizaciÃ³n de Consultas**
   - MÃ©todo: NLP con clasificaciÃ³n automÃ¡tica
   - Input: Texto de transcripciones
   - Categories: TÃ©cnico, financiero, producto, etc.

### Notebooks de AnÃ¡lisis

- `analytics/exploratory/eda_customer_satisfaction.ipynb`
- `analytics/nlp_models/sentiment_analysis.ipynb`
- `analytics/ml_models/satisfaction_prediction.ipynb`

## ğŸ“Š Dashboards y VisualizaciÃ³n

### QuickSight Dashboards

1. **ğŸ“ˆ Executive Dashboard**
   - KPIs principales
   - Tendencias temporales
   - Comparativas por canal

2. **ğŸ” Operational Dashboard**
   - MÃ©tricas en tiempo real
   - Alertas de satisfacciÃ³n
   - DistribuciÃ³n de workload

3. **ğŸ‘¥ Customer Insights**
   - SegmentaciÃ³n de clientes
   - Journey mapping
   - Sentiment analysis

### Acceso a Dashboards

```bash
# URL QuickSight (ejemplo)
https://us-east-1.quicksight.aws.amazon.com/sn/dashboards/customer-satisfaction-executive
```

## ğŸ§ª Testing

### Ejecutar Tests

```bash
# Tests unitarios
pytest tests/ingestion_tests/

# Tests de integraciÃ³n
pytest tests/integration_tests/

# Tests de calidad de datos
python tests/data_quality_tests.py
```

### Cobertura de Tests

- âœ… Ingesta de datos
- âœ… Transformaciones ETL
- âœ… Calidad de datos
- âœ… Modelos ML
- âœ… APIs

## ğŸš€ CI/CD

### GitHub Actions

- **ğŸ” Code Quality**: Linting, formatting, security scan
- **ğŸ§ª Testing**: Unit tests, integration tests
- **ğŸ—ï¸ Infrastructure**: Terraform validate/plan
- **ğŸ“¦ Deployment**: Automated deployment to dev/staging/prod

### Pipeline Flow

```
PR Created â†’ Code Quality â†’ Tests â†’ Terraform Plan â†’ Review â†’ Merge â†’ Deploy
```

## ğŸ›¡ï¸ Seguridad y Compliance

### Medidas de Seguridad

- **ğŸ”’ Cifrado**: Datos en reposo (S3) y en trÃ¡nsito (TLS)
- **ğŸ›¡ï¸ IAM**: Roles y polÃ­ticas de menor privilegio
- **ğŸ” Secrets**: AWS Secrets Manager para credenciales
- **ğŸ“Š AuditorÃ­a**: CloudTrail para logging de accesos
- **ğŸš« AnonimizaciÃ³n**: Scripts para protecciÃ³n de PII

### Compliance

- **GDPR**: AnonimizaciÃ³n y derecho al olvido
- **SOX**: RetenciÃ³n de datos y auditorÃ­a
- **ISO 27001**: GestiÃ³n de seguridad de la informaciÃ³n

## ğŸ“š DocumentaciÃ³n Adicional

- [ğŸ—ï¸ GuÃ­a de Arquitectura](docs/arquitectura.md)
- [ğŸ”§ Manual de ConfiguraciÃ³n](docs/configuracion.md)
- [ğŸ“Š Diccionario de Datos](docs/diccionario_datos.md)
- [ğŸ§  DocumentaciÃ³n de Modelos ML](docs/modelos_ml.md)
- [ğŸš€ GuÃ­a de Deployment](docs/deployment.md)

## ğŸ¤ Contribuir

### CÃ³mo Contribuir

1. Fork el repositorio
2. Crear branch de feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push al branch (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

### EstÃ¡ndares de CÃ³digo

- **Python**: PEP 8, type hints, docstrings
- **SQL**: Estilo estÃ¡ndar, comentarios
- **Terraform**: DocumentaciÃ³n de variables
- **Git**: Commits convencionales

## ğŸ“ Soporte y Contacto

### Equipo de Desarrollo

- **ğŸ‘¨â€ğŸ’¼ Product Owner**: [Nombre] - product@empresa.com
- **ğŸ‘©â€ğŸ’» Tech Lead**: [Nombre] - tech.lead@empresa.com
- **ğŸ‘¨â€ğŸ”¬ Data Scientist**: [Nombre] - data.scientist@empresa.com
- **â˜ï¸ DevOps Engineer**: [Nombre] - devops@empresa.com

### Canales de Soporte

- **ğŸ« Issues**: GitHub Issues para bugs y feature requests
- **ğŸ’¬ Slack**: #customer-analytics para discusiones
- **ğŸ“§ Email**: analytics-team@empresa.com
- **ğŸ“– Wiki**: Confluence space para documentaciÃ³n extendida

## ğŸ“ Licencia

Este proyecto estÃ¡ licenciado bajo la [Licencia MIT](LICENSE) - ver el archivo LICENSE para detalles.

## ğŸ™ Agradecimientos

- **AWS**: Por la infraestructura cloud robusta
- **Apache Spark**: Por el procesamiento distribuido
- **Terraform**: Por la infraestructura como cÃ³digo
- **Kaggle**: Por los datasets de referencia
- **CFPB**: Por los datos pÃºblicos de quejas bancarias

---

<div align="center">

**ğŸ“Š Customer Satisfaction Analytics**

*Transformando datos en insights accionables para mejorar la experiencia del cliente*

[ğŸš€ Demo](https://demo.customer-analytics.com) â€¢ [ğŸ“š Docs](https://docs.customer-analytics.com) â€¢ [ğŸ“Š Dashboards](https://dashboards.customer-analytics.com)

</div>
