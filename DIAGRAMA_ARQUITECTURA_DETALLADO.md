# ğŸ—ï¸ Diagrama de Arquitectura Detallado - Customer Satisfaction Analytics

## ğŸ“‹ Resumen Ejecutivo

**Sistema completo de anÃ¡lisis de satisfacciÃ³n del cliente** implementado con arquitectura hÃ­brida (Local + AWS) optimizado para **costo $0.00** usando AWS Free Tier y servicios externos gratuitos.

**Datos totales procesados:** 171,031 registros
**Costo operacional:** $0.00/mes
**PerÃ­odo de datos:** 2023-2024 (730 dÃ­as)

---

## ğŸ¯ Arquitectura General del Sistema

```mermaid
graph TB
    subgraph "ğŸ¢ CAPA DE DATOS"
        A1[ğŸ‘¥ Clientes<br/>15,000 registros] 
        A2[ğŸ« Tickets Soporte<br/>75,000 registros]
        A3[ğŸ“‹ Encuestas Post-AtenciÃ³n<br/>21,531 respuestas]
        A4[â­ ReseÃ±as Online<br/>8,000 reseÃ±as]
        A5[ğŸ“ Llamadas Call Center<br/>30,000 llamadas]
        A6[ğŸ“– Libro Reclamaciones<br/>1,500 reclamos]
        A7[ğŸ’¬ Mensajes WhatsApp<br/>20,000 mensajes]
    end
    
    subgraph "ğŸ”„ CAPA DE PROCESAMIENTO"
        B1[ğŸ¤– Data Simulator<br/>Python + Faker]
        B2[âš™ï¸ Data Processing<br/>PySpark Jobs]
        B3[ğŸ§  Sentiment Analyzer<br/>NLTK/spaCy]
        B4[ğŸ“Š ML Predictor<br/>Satisfaction Models]
    end
    
    subgraph "ğŸ“¦ CAPA DE ALMACENAMIENTO"
        C1[ğŸ’¾ Local Storage<br/>CSV + Parquet]
        C2[â˜ï¸ S3 Data Lake<br/>Raw + Processed]
        C3[ğŸ“š Glue Catalog<br/>Schema Management]
        C4[ğŸ” Athena<br/>Query Engine]
    end
    
    subgraph "ğŸ“Š CAPA DE PRESENTACIÃ“N"
        D1[ğŸ¨ Streamlit Dashboard<br/>localhost:8501]
        D2[ğŸ“ˆ Plotly Charts<br/>Interactive Viz]
        D3[ğŸ“± Responsive UI<br/>Mobile Ready]
        D4[ğŸ§  AI Insights<br/>Auto-generated]
    end
    
    subgraph "ğŸ›¡ï¸ CAPA DE MONITOREO"
        E1[ğŸ’° Cost Monitor<br/>AWS Usage Tracking]
        E2[ğŸ”” Alertas<br/>Email + Slack]
        E3[ğŸ“Š CloudWatch<br/>Metrics + Logs]
        E4[ğŸ§¹ Auto Cleanup<br/>Data Lifecycle]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    A4 --> B1
    A5 --> B1
    A6 --> B1
    A7 --> B1
    
    B1 --> C1
    B1 --> C2
    B2 --> C3
    B3 --> C4
    B4 --> C4
    
    C1 --> D1
    C2 --> D1
    C3 --> D1
    C4 --> D1
    
    D1 --> D2
    D2 --> D3
    D3 --> D4
    
    C2 --> E1
    C4 --> E1
    E1 --> E2
    E1 --> E3
    E1 --> E4
    
    style A1 fill:#e3f2fd
    style A2 fill:#e3f2fd
    style A3 fill:#e3f2fd
    style A4 fill:#e3f2fd
    style A5 fill:#e3f2fd
    style A6 fill:#e3f2fd
    style A7 fill:#e3f2fd
    style B1 fill:#f3e5f5
    style B2 fill:#f3e5f5
    style B3 fill:#f3e5f5
    style B4 fill:#f3e5f5
    style C1 fill:#e8f5e8
    style C2 fill:#e8f5e8
    style C3 fill:#e8f5e8
    style C4 fill:#e8f5e8
    style D1 fill:#fff3e0
    style D2 fill:#fff3e0
    style D3 fill:#fff3e0
    style D4 fill:#fff3e0
    style E1 fill:#ffebee
    style E2 fill:#ffebee
    style E3 fill:#ffebee
    style E4 fill:#ffebee
```

---

## ğŸ—ï¸ Arquitectura de Infraestructura AWS

```mermaid
graph TB
    subgraph "ğŸŒ AWS CLOUD (Free Tier)"
        subgraph "ğŸ“¦ Storage Layer"
            S1[S3 Data Lake<br/>customer-satisfaction-data-lake-dev<br/>ğŸ“Š <100MB de 5GB]
            S2[S3 Athena Results<br/>athena-results-dev<br/>ğŸ“Š <10MB]
            S3[S3 Logs Bucket<br/>logs-dev<br/>ğŸ“Š <50MB]
        end
        
        subgraph "ğŸ” Analytics Layer"
            A1[Athena Workgroup<br/>customer-satisfaction-wg<br/>ğŸ“Š <5GB scan/mes]
            A2[Glue Catalog<br/>customer_satisfaction_db<br/>ğŸ“Š Schema Discovery]
            A3[Glue ETL Jobs<br/>ğŸ“Š <2 hrs/mes de 1M]
        end
        
        subgraph "ğŸ“Š Monitoring Layer"
            M1[CloudWatch Metrics<br/>ğŸ“Š <10 custom metrics]
            M2[CloudWatch Logs<br/>ğŸ“Š <5GB logs/mes]
            M3[AWS Budget<br/>ğŸ’° Alert at $0.50]
        end
        
        subgraph "ğŸ›¡ï¸ Security Layer"
            SEC1[IAM Roles<br/>Glue Service Role]
            SEC2[S3 Encryption<br/>AES-256]
            SEC3[VPC Endpoints<br/>Optional]
        end
    end
    
    subgraph "ğŸ’» LOCAL ENVIRONMENT"
        L1[ğŸ–¥ï¸ Development<br/>Windows 11]
        L2[ğŸ Python venv<br/>.venv environment]
        L3[ğŸ“Š Streamlit Server<br/>Port 8501]
        L4[ğŸ’¾ Local Data<br/>data/simulated/]
    end
    
    subgraph "ğŸŒ EXTERNAL SERVICES (Free)"
        EXT1[ğŸ“§ Email Alerts<br/>SMTP Gmail]
        EXT2[ğŸ’¬ Slack Webhook<br/>Notifications]
        EXT3[ğŸ¤— Hugging Face<br/>ML Models]
        EXT4[ğŸ”„ GitHub Actions<br/>CI/CD Pipeline]
    end
    
    L3 --> S1
    A3 --> S1
    S1 --> A1
    A1 --> S2
    A2 --> A1
    
    M1 --> EXT1
    M2 --> EXT2
    M3 --> EXT1
    
    SEC1 --> A3
    SEC2 --> S1
    
    L4 --> L3
    L2 --> L3
    L1 --> L2
    
    style S1 fill:#e3f2fd
    style S2 fill:#e3f2fd
    style S3 fill:#e3f2fd
    style A1 fill:#f3e5f5
    style A2 fill:#f3e5f5
    style A3 fill:#f3e5f5
    style M1 fill:#fff3e0
    style M2 fill:#fff3e0
    style M3 fill:#fff3e0
    style SEC1 fill:#e8f5e8
    style SEC2 fill:#e8f5e8
    style SEC3 fill:#e8f5e8
    style L1 fill:#ffebee
    style L2 fill:#ffebee
    style L3 fill:#ffebee
    style L4 fill:#ffebee
    style EXT1 fill:#f0f4c3
    style EXT2 fill:#f0f4c3
    style EXT3 fill:#f0f4c3
    style EXT4 fill:#f0f4c3
```

---

## ğŸ“Š Flujo de Datos Detallado

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ Usuario
    participant DS as ğŸ¤– Data Simulator
    participant LS as ğŸ’¾ Local Storage
    participant S3 as â˜ï¸ S3 Data Lake
    participant GL as ğŸ”§ Glue ETL
    participant AT as ğŸ” Athena
    participant ST as ğŸ¨ Streamlit
    participant CM as ğŸ’° Cost Monitor
    
    Note over DS: 1. GENERACIÃ“N DE DATOS
    U->>DS: python data_simulator.py
    DS->>DS: Generate 171K+ records
    DS->>LS: Save CSV + Parquet
    DS->>U: âœ… Data generation complete
    
    Note over S3: 2. CARGA A AWS (Opcional)
    U->>S3: Upload via s3_uploader.py
    S3->>GL: Trigger crawler
    GL->>AT: Update catalog schema
    AT->>S3: Store query results
    
    Note over ST: 3. DASHBOARD EXECUTION
    U->>ST: streamlit run app.py
    ST->>LS: Load local data
    ST->>AT: Query AWS (if available)
    ST->>ST: Generate visualizations
    ST->>U: ğŸ“Š Interactive dashboard
    
    Note over CM: 4. MONITOREO CONTINUO
    CM->>S3: Check storage usage
    CM->>AT: Check scan usage
    CM->>GL: Check DPU hours
    CM->>CM: Calculate costs
    CM->>U: ğŸš¨ Alerts if needed
    
    Note over U: 5. INSIGHTS GENERATION
    ST->>ST: AI analysis
    ST->>U: ğŸ§  Auto-generated insights
```

---

## ğŸ—ï¸ Componentes TÃ©cnicos Detallados

### ğŸ“¦ 1. Capa de Datos (Data Layer)

| Componente | DescripciÃ³n | Volumen | Formato |
|------------|-------------|---------|---------|
| **Clientes** | Base de datos de clientes del banco | 15,000 registros | CSV/Parquet |
| **Tickets Soporte** | Interacciones de servicio al cliente | 75,000 tickets | CSV/Parquet |
| **Encuestas Post-AtenciÃ³n** | Feedback post-resoluciÃ³n | 21,531 respuestas | CSV/Parquet |
| **ReseÃ±as Online** | Comentarios de plataformas digitales | 8,000 reseÃ±as | CSV/Parquet |
| **Llamadas Call Center** | Logs de conversaciones telefÃ³nicas | 30,000 llamadas | CSV/Parquet |
| **Libro Reclamaciones** | Quejas oficiales (Indecopi) | 1,500 reclamos | CSV/Parquet |
| **Mensajes WhatsApp** | Conversaciones WhatsApp Business | 20,000 mensajes | CSV/Parquet |

**CaracterÃ­sticas de los datos:**
- âœ… Completitud: 85.5%
- âœ… AnonimizaciÃ³n: Completa
- âœ… Cumplimiento: Indecopi PerÃº
- âœ… PerÃ­odo: 2023-2024 (730 dÃ­as)

### ğŸ”„ 2. Capa de Procesamiento (Processing Layer)

#### ğŸ¤– Data Simulator (`scripts/data_simulator.py`)
```python
# CaracterÃ­sticas principales:
- GeneraciÃ³n de datos sintÃ©ticos bancarios realistas
- Seed fijo (42) para reproducibilidad
- Distribuciones estadÃ­sticamente correctas
- Correlaciones realistas entre variables
- Soporte para mÃºltiples locales (es_ES, es_MX)
```

#### âš™ï¸ Data Processing (`processing/pyspark_jobs/`)
```python
# Funcionalidades:
- ETL con PySpark para big data
- Limpieza y normalizaciÃ³n de datos
- CreaciÃ³n de mÃ©tricas KPI
- Particionado por fecha y canal
```

#### ğŸ§  ML Components
```python
# Modelos disponibles:
- AnÃ¡lisis de sentimientos (NLTK/spaCy)
- PredicciÃ³n de satisfacciÃ³n
- ClasificaciÃ³n NPS
- DetecciÃ³n de anomalÃ­as
```

### ğŸ“¦ 3. Capa de Almacenamiento (Storage Layer)

#### ğŸ’¾ Local Storage
```
data/simulated/
â”œâ”€â”€ clientes.csv (4.2MB)
â”œâ”€â”€ tickets_soporte.csv (28.5MB)
â”œâ”€â”€ encuestas_post_atencion.csv (3.8MB)
â”œâ”€â”€ resenas_online.csv (2.1MB)
â”œâ”€â”€ llamadas_call_center.csv (8.9MB)
â”œâ”€â”€ libro_reclamaciones.csv (456KB)
â”œâ”€â”€ mensajes_whatsapp.csv (6.2MB)
â””â”€â”€ resumen_generacion.json (metadata)
```

#### â˜ï¸ AWS S3 Data Lake
```
Bucket Structure:
customer-satisfaction-data-lake-dev/
â”œâ”€â”€ raw-data/
â”‚   â”œâ”€â”€ clientes/
â”‚   â”œâ”€â”€ tickets/
â”‚   â””â”€â”€ surveys/
â”œâ”€â”€ processed-data/
â”‚   â”œâ”€â”€ daily-metrics/
â”‚   â””â”€â”€ aggregations/
â””â”€â”€ curated-data/
    â”œâ”€â”€ kpi-dashboard/
    â””â”€â”€ ml-features/
```

**ConfiguraciÃ³n de seguridad:**
- âœ… Versionado habilitado
- âœ… Cifrado AES-256
- âœ… Lifecycle policies (30 dÃ­as)
- âœ… Prevent destroy = true

### ğŸ” 4. Capa de Analytics

#### ğŸ” Amazon Athena
```sql
-- ConfiguraciÃ³n del Workgroup:
WorkGroup: customer-satisfaction-workgroup-dev
Query Limit: 1GB per query
Result Location: s3://athena-results-dev/
Cost Control: Enabled
```

#### ğŸ“š AWS Glue
```yaml
Database: customer_satisfaction_db_155537880398
Tables:
  - clientes
  - tickets_soporte  
  - encuestas_post_atencion
  - resenas_online
  - llamadas_call_center
  - libro_reclamaciones
  - mensajes_whatsapp
```

### ğŸ“Š 5. Capa de PresentaciÃ³n (Presentation Layer)

#### ğŸ¨ Streamlit Dashboard (`analytics/streamlit_dashboard/app.py`)

**CaracterÃ­sticas principales:**
- âœ… 793 lÃ­neas de cÃ³digo Python
- âœ… ConexiÃ³n AWS Athena opcional
- âœ… Datos simulados como fallback
- âœ… Cache inteligente (1 hora TTL)
- âœ… Responsive design
- âœ… MÃºltiples tipos de visualizaciÃ³n

**Componentes del Dashboard:**
1. **KPI Cards**: MÃ©tricas principales en tiempo real
2. **Trend Analysis**: EvoluciÃ³n temporal de satisfacciÃ³n
3. **Channel Analysis**: ComparaciÃ³n por canal de atenciÃ³n
4. **NPS Analysis**: Net Promoter Score y distribuciÃ³n
5. **Agent Performance**: Rendimiento individual de agentes
6. **AI Insights**: Insights generados automÃ¡ticamente

**TecnologÃ­as utilizadas:**
- Streamlit 1.28+
- Plotly 5.17+ (grÃ¡ficos interactivos)
- Pandas 2.0+ (manipulaciÃ³n de datos)
- Boto3 1.29+ (AWS SDK)
- NumPy 1.24+ (cÃ¡lculos numÃ©ricos)

### ğŸ›¡ï¸ 6. Capa de Monitoreo (Monitoring Layer)

#### ğŸ’° AWS Cost Monitor (`scripts/aws_cost_monitor.py`)

**CaracterÃ­sticas:**
- âœ… 803 lÃ­neas de cÃ³digo Python
- âœ… Monitoreo en tiempo real de usage
- âœ… Alertas automÃ¡ticas (email + Slack)
- âœ… Limpieza automÃ¡tica de datos antiguos
- âœ… Reportes detallados en Markdown

**LÃ­mites monitoreados:**
- S3 Storage: 5GB (Free Tier)
- Athena Scans: 5GB/mes (Free Tier)
- Glue DPU Hours: 1M horas/mes (Free Tier)
- CloudWatch Logs: 5GB/mes (Free Tier)

**Thresholds de alerta:**
- âš ï¸ Warning: 80% de uso Free Tier
- ğŸš¨ Critical: 95% de uso Free Tier
- ğŸ§¹ Auto-cleanup: >90 dÃ­as de antigÃ¼edad

---

## ğŸ”§ Terraform Infrastructure as Code

### ğŸ“‹ Recursos Definidos (`infra/terraform/main.tf`)

```hcl
# Componentes principales (232 lÃ­neas):
âœ… 3x S3 Buckets (Data Lake, Athena Results, Logs)
âœ… 1x Glue Database
âœ… 1x Athena Workgroup  
âœ… 1x IAM Role (Glue Service)
âœ… 1x AWS Budget (Cost Control)
âœ… Security configurations (Encryption, Versioning)
âœ… Lifecycle policies (Auto cleanup)
```

**Variables configuradas:**
```hcl
aws_region = "us-east-1"
aws_account_id = "155537880398"
project_name = "customer-satisfaction-analytics"
environment = "dev"
budget_amount = 1.00  # Alert at $1
notification_email = "paradox1100p@gmail.com"
```

---

## ğŸ“Š MÃ©tricas de Negocio y KPIs

### ğŸ“ˆ KPIs Principales Calculados

| KPI | Valor Actual | FÃ³rmula | Fuente |
|-----|-------------|---------|---------|
| **SatisfacciÃ³n Promedio** | 3.22/5.0 | AVG(satisfaccion_cliente) | tickets_soporte |
| **NPS Score** | 5.0 | (Promotores - Detractores) / Total * 100 | encuestas_post_atencion |
| **Tasa de ResoluciÃ³n** | 82% | COUNT(estado='resuelto') / COUNT(total) | tickets_soporte |
| **Tiempo Promedio** | 15.2 min | AVG(tiempo_resolucion_horas) * 60 | tickets_soporte |

### ğŸ“Š DistribuciÃ³n por Canales

| Canal | Tickets | % Total | Sat. Promedio |
|-------|---------|---------|---------------|
| **TelÃ©fono** | 26,167 | 34.9% | 3.18/5.0 |
| **Chat Web** | 18,639 | 24.9% | 3.25/5.0 |
| **Email** | 11,257 | 15.0% | 3.21/5.0 |
| **Sucursal** | 9,065 | 12.1% | 3.28/5.0 |
| **App MÃ³vil** | 6,144 | 8.2% | 3.19/5.0 |
| **WhatsApp** | 3,728 | 5.0% | 3.24/5.0 |

### ğŸ¦ DistribuciÃ³n por Departamentos

| Departamento | Tickets | % Total | Complejidad |
|--------------|---------|---------|-------------|
| **Tarjetas** | 22,397 | 29.9% | Media |
| **PrÃ©stamos** | 18,649 | 24.9% | Alta |
| **Cuentas** | 15,271 | 20.4% | Baja |
| **Inversiones** | 11,221 | 15.0% | Alta |
| **Seguros** | 7,462 | 9.9% | Media |

---

## ğŸ’° AnÃ¡lisis de Costos Detallado

### ğŸ†“ Uso Actual de AWS Free Tier

| Servicio | LÃ­mite Free Tier | Uso Estimado | % Utilizado | Costo Extra |
|----------|------------------|--------------|-------------|-------------|
| **S3 Storage** | 5 GB/mes | <100 MB | <2% | $0.00 |
| **Athena Scans** | 5 GB/mes | <10 MB | <0.2% | $0.00 |
| **Glue DPU-Hours** | 1M horas/mes | <2 horas | <0.0002% | $0.00 |
| **CloudWatch Logs** | 5 GB/mes | <50 MB | <1% | $0.00 |
| **CloudWatch Metrics** | 10 metrics/mes | 3 metrics | 30% | $0.00 |

**ğŸ’š Costo total mensual: $0.00**

### ğŸ›¡ï¸ Protecciones Anti-Costos Implementadas

1. **AWS Budget**: Alerta automÃ¡tica si costo > $0.50
2. **Query Limits**: MÃ¡ximo 1GB por consulta Athena
3. **Lifecycle Policies**: Auto-delete datos >30 dÃ­as
4. **Monitoring Script**: EjecuciÃ³n diaria del cost monitor
5. **Resource Limits**: MÃ¡ximo 3 buckets S3

---

## ğŸš€ GuÃ­a de Despliegue

### ğŸ  1. Despliegue Local (Recomendado para desarrollo)

```bash
# 1. Clonar repositorio
git clone https://github.com/MilaPacompiaM/customer-satisfaction-analytics.git
cd customer-satisfaction-analytics

# 2. Configurar entorno Python
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements-streamlit.txt

# 3. Generar datos simulados (primera vez)
python scripts/data_simulator.py

# 4. Ejecutar dashboard
streamlit run streamlit_app.py

# 5. Acceder a http://localhost:8501
```

### â˜ï¸ 2. Despliegue AWS (Para producciÃ³n)

```bash
# 1. Configurar AWS CLI
aws configure
# Access Key: [TU_ACCESS_KEY]
# Secret Key: [TU_SECRET_KEY]
# Region: us-east-1

# 2. Desplegar infraestructura
cd infra/terraform/
terraform init
terraform plan
terraform apply

# 3. Subir datos a S3
python scripts/s3_uploader.py

# 4. Ejecutar Glue crawler
aws glue start-crawler --name customer-satisfaction-crawler

# 5. Verificar en dashboard (conectarÃ¡ automÃ¡ticamente a AWS)
```

### ğŸ’° 3. Monitoreo de Costos

```bash
# Ejecutar monitor de costos
python scripts/aws_cost_monitor.py --email tu@email.com

# Monitor automÃ¡tico diario (Windows Task Scheduler)
schtasks /create /tn "AWS Cost Monitor" /tr "python scripts/aws_cost_monitor.py" /sc daily
```

---

## ğŸ”§ TecnologÃ­as y Dependencias

### ğŸ Python Dependencies

```python
# Core Framework
streamlit>=1.28.0          # Dashboard web framework
pandas>=2.0.0              # Data manipulation
numpy>=1.24.0              # Numerical computing
plotly>=5.17.0            # Interactive visualizations

# AWS Integration  
boto3>=1.29.0             # AWS SDK
awscli>=1.32.0           # AWS CLI tools

# Data Generation
faker>=20.0.0             # Synthetic data generation
uuid4                     # Unique identifiers

# ML/AI Components
nltk>=3.8                 # Natural language processing
spacy>=3.7.0              # Advanced NLP
scikit-learn>=1.3.0       # Machine learning

# Monitoring & Alerts
requests>=2.31.0          # HTTP requests for webhooks
smtplib                   # Email sending
logging                   # Application logging
```

### ğŸ—ï¸ Infrastructure Dependencies

```yaml
# Terraform Providers
terraform >= 1.0
hashicorp/aws ~> 5.0
hashicorp/random ~> 3.1

# AWS Services
S3: Storage buckets
Athena: Query engine  
Glue: Data catalog and ETL
CloudWatch: Monitoring and logs
IAM: Access management
Budgets: Cost control
```

### ğŸŒ External Services (Free Tier)

```yaml
# Development & CI/CD
GitHub Actions: 2000 min/month
Docker Hub: Unlimited public repos

# ML & AI
Google Colab: Free GPU/TPU access
Hugging Face: Free model hosting
Kaggle: Free compute kernels

# Monitoring & Alerts
Gmail SMTP: Free email sending
Slack Webhooks: Free notifications
Discord Webhooks: Alternative notifications

# Visualization & Hosting
Streamlit Cloud: Free app hosting
Grafana Cloud: 10K series free
```

---

## ğŸ”„ Flujos de Trabajo y Procesos

### ğŸ“Š 1. Proceso de GeneraciÃ³n de Datos

```python
# Ejecutado por: scripts/data_simulator.py
Paso 1: Generar base de clientes (15K)
    â”œâ”€â”€ Perfiles realistas por edad y segmento
    â”œâ”€â”€ Productos bancarios asociados  
    â””â”€â”€ Canales de preferencia

Paso 2: Simular interacciones (156K)
    â”œâ”€â”€ Tickets de soporte (75K)
    â”œâ”€â”€ Llamadas call center (30K)
    â”œâ”€â”€ Mensajes WhatsApp (20K)
    â”œâ”€â”€ ReseÃ±as online (8K)
    â””â”€â”€ Reclamos oficiales (1.5K)

Paso 3: Generar encuestas (21.5K)
    â”œâ”€â”€ NPS scores realistas
    â”œâ”€â”€ CorrelaciÃ³n con satisfacciÃ³n
    â””â”€â”€ MÃºltiples canales de respuesta

Paso 4: Exportar datos
    â”œâ”€â”€ Formatos: CSV + Parquet
    â”œâ”€â”€ Metadata: JSON summary
    â””â”€â”€ UbicaciÃ³n: data/simulated/
```

### ğŸ”„ 2. Pipeline ETL (Opcional AWS)

```sql
-- Ejecutado por: AWS Glue Jobs
EXTRACT:
  â† Raw CSV files from S3 raw-data/
  
TRANSFORM:
  â”œâ”€â”€ Data cleaning and validation
  â”œâ”€â”€ KPI calculations
  â”œâ”€â”€ Sentiment analysis
  â”œâ”€â”€ NPS score computation
  â””â”€â”€ Date partitioning

LOAD:  
  â†’ S3 processed-data/ (Parquet format)
  â†’ S3 curated-data/ (Analytics-ready)
  â†’ Glue Catalog (Schema updates)
```

### ğŸ“Š 3. Dashboard Rendering Process

```python
# Ejecutado por: streamlit_dashboard/app.py
Inicio:
  â”œâ”€â”€ Load configuration and setup UI
  â”œâ”€â”€ Initialize AWS clients (optional)
  â””â”€â”€ Setup caching (1 hour TTL)

Data Loading:
  â”œâ”€â”€ Try AWS Athena connection
  â”œâ”€â”€ Fallback to local simulated data
  â””â”€â”€ Apply user filters (date, channel)

Visualizations:
  â”œâ”€â”€ Generate KPI cards
  â”œâ”€â”€ Create trend charts (Plotly)
  â”œâ”€â”€ Build channel analysis
  â”œâ”€â”€ Compute NPS distribution
  â”œâ”€â”€ Analyze agent performance
  â””â”€â”€ Generate AI insights

Output:
  â””â”€â”€ Interactive web dashboard (port 8501)
```

### ğŸ’° 4. Cost Monitoring Workflow

```python
# Ejecutado por: scripts/aws_cost_monitor.py
Monitoring:
  â”œâ”€â”€ Check S3 usage (storage + requests)
  â”œâ”€â”€ Monitor Athena scans
  â”œâ”€â”€ Track Glue DPU hours
  â””â”€â”€ Assess CloudWatch usage

Analysis:
  â”œâ”€â”€ Calculate cost estimates
  â”œâ”€â”€ Compare vs Free Tier limits
  â””â”€â”€ Generate usage percentages

Alerting:
  â”œâ”€â”€ Warning: >80% Free Tier usage
  â”œâ”€â”€ Critical: >95% Free Tier usage
  â””â”€â”€ Send notifications (email/Slack)

Actions:
  â”œâ”€â”€ Auto-cleanup old data (>90 days)
  â”œâ”€â”€ Generate detailed reports
  â””â”€â”€ Log all activities
```

---

## ğŸ¯ Roadmap y Futuras Mejoras

### âœ… Completado (v1.0)
- [x] Sistema completo de generaciÃ³n de datos sintÃ©ticos
- [x] Dashboard interactivo con Streamlit
- [x] Infraestructura Terraform para AWS
- [x] Monitoreo de costos automÃ¡tico
- [x] DocumentaciÃ³n tÃ©cnica completa

### ğŸ”„ En Desarrollo (v1.1)
- [ ] API REST para integraciÃ³n externa
- [ ] Modelos ML avanzados (BERT para sentiment analysis)  
- [ ] Dashboard mobile-responsive mejorado
- [ ] CI/CD pipeline con GitHub Actions
- [ ] Tests unitarios y de integraciÃ³n

### ğŸ“‹ Planificado (v1.2)
- [ ] Conectores para sistemas bancarios reales
- [ ] Real-time streaming con Kinesis
- [ ] Alertas inteligentes con ML
- [ ] Multi-tenant support
- [ ] IntegraciÃ³n con Microsoft Power BI

### ğŸš€ VisiÃ³n Futura (v2.0)
- [ ] Microservicios con Docker/Kubernetes
- [ ] GraphQL API
- [ ] Machine Learning automatizado (AutoML)
- [ ] IntegraciÃ³n con GPT-4 para insights
- [ ] Compliance automÃ¡tico con regulaciones

---

## ğŸ“ Soporte y Contacto

### ğŸ‘¥ Equipo del Proyecto

| Rol | Responsable | Contacto |
|-----|-------------|----------|
| **Project Owner** | MilaPacompiaM | GitHub Issues |
| **Technical Lead** | Edgardo | Rama: `Edgardo` |
| **AWS Account** | 155537880398 | paradox1100p@gmail.com |

### ğŸ”§ Comandos de Troubleshooting

```bash
# Verificar estado del proyecto
python --version                    # Python 3.8+
streamlit --version                # Streamlit 1.28+
aws --version                      # AWS CLI 2.0+
terraform --version               # Terraform 1.0+

# DiagnÃ³stico de datos
ls -la data/simulated/            # Verificar archivos generados
python -c "import pandas as pd; print(pd.read_csv('data/simulated/clientes.csv').info())"

# Verificar AWS connectivity
aws s3 ls                         # Listar buckets S3
aws athena list-work-groups       # Verificar Athena
python scripts/aws_cost_monitor.py --quiet  # Check costs

# Restart services
taskkill /f /im python.exe        # Stop all Python processes
streamlit run streamlit_app.py    # Restart dashboard
```

### ğŸ“§ Soporte TÃ©cnico

**Para issues tÃ©cnicos:** https://github.com/MilaPacompiaM/customer-satisfaction-analytics/issues

**Para alertas AWS:** paradox1100p@gmail.com

**DocumentaciÃ³n:** Ver archivos `*.md` en el repositorio

---

## ğŸ“ Notas de ImplementaciÃ³n

### âš ï¸ Consideraciones Importantes

1. **Datos Simulados**: Los datos son completamente sintÃ©ticos y no representan informaciÃ³n real de clientes
2. **AWS Free Tier**: El proyecto estÃ¡ optimizado para mantenerse dentro de los lÃ­mites gratuitos
3. **Seguridad**: Todas las credenciales deben configurarse como variables de entorno
4. **Escalabilidad**: El diseÃ±o permite escalar a datos reales sin cambios arquitectÃ³nicos mayores
5. **Compliance**: Cumple con regulaciones Indecopi para el sector bancario peruano

### ğŸ” Security Best Practices

```yaml
Implementadas:
  âœ… Cifrado S3 con AES-256
  âœ… IAM roles con permisos mÃ­nimos
  âœ… VPC endpoints (opcional)
  âœ… Versionado de buckets habilitado
  âœ… Lifecycle policies para cleanup
  âœ… Budget alerts para cost control

Recomendadas:
  ğŸ”² AWS CloudTrail para auditorÃ­a
  ğŸ”² AWS GuardDuty para threat detection  
  ğŸ”² AWS Config para compliance
  ğŸ”² RotaciÃ³n automÃ¡tica de credenciales
  ğŸ”² Multi-factor authentication (MFA)
```

### ğŸ“Š Performance Optimizations

```python
# Streamlit Caching
@st.cache_data(ttl=3600)  # 1 hora
def load_data():
    # Datos cacheados por 1 hora
    
# Athena Query Optimization
- LIMIT clauses automÃ¡ticos
- Particionado por fecha
- Formato Parquet con compresiÃ³n
- Columnar storage para analytics

# Local Development
- CSV + Parquet dual storage
- Fallback a datos simulados
- Progressive loading de visualizaciones
```

---

**ğŸ¯ ConclusiÃ³n:**

Este diagrama de arquitectura detalla un sistema completo de anÃ¡lisis de satisfacciÃ³n del cliente que combina:

âœ… **Costo $0.00/mes** usando AWS Free Tier
âœ… **171,031 registros** de datos bancarios sintÃ©ticos realistas
âœ… **Dashboard interactivo** con Streamlit y Plotly
âœ… **Monitoreo automÃ¡tico** de costos y recursos
âœ… **Infraestructura como cÃ³digo** con Terraform
âœ… **ML/AI capabilities** para insights automÃ¡ticos
âœ… **Escalabilidad** para datos reales de producciÃ³n

El sistema estÃ¡ listo para producciÃ³n y puede adaptarse fÃ¡cilmente a necesidades especÃ­ficas del negocio bancario.

---

*ğŸ“… Documento generado el: 2025-09-04*  
*ğŸ”„ VersiÃ³n: 1.0*  
*ğŸ‘¤ Autor: Customer Satisfaction Analytics Team*