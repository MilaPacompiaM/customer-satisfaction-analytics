#!/usr/bin/env python3
"""
Setup automÃ¡tico para Customer Satisfaction Analytics - Modo Capa Gratuita
Script para configurar y optimizar el proyecto para mantenerse en AWS Free Tier.

Funciones:
- ğŸ”§ ConfiguraciÃ³n automÃ¡tica de lÃ­mites
- ğŸ“Š InstalaciÃ³n del dashboard Streamlit gratuito
- âš ï¸ ConfiguraciÃ³n de alertas automÃ¡ticas
- ğŸ§¹ Scripts de limpieza programada
- ğŸ’° Optimizaciones de costo
"""

import os
import sys
import subprocess
import json
import shutil
from pathlib import Path
import argparse
import logging
from datetime import datetime


class FreeTierSetup:
    """Configurador para modo capa gratuita."""
    
    def __init__(self, project_root: str = "."):
        """
        Inicializar configurador.
        
        Args:
            project_root: Directorio raÃ­z del proyecto
        """
        self.project_root = Path(project_root).absolute()
        self.setup_logging()
        
    def setup_logging(self):
        """Configurar logging."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def check_prerequisites(self) -> bool:
        """Verificar prerequisites del sistema."""
        self.logger.info("ğŸ” Verificando prerequisites...")
        
        # Verificar Python
        if sys.version_info < (3, 8):
            self.logger.error("âŒ Se requiere Python 3.8 o superior")
            return False
        
        # Verificar pip
        try:
            subprocess.run(['pip', '--version'], check=True, capture_output=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.logger.error("âŒ pip no estÃ¡ instalado")
            return False
        
        # Verificar AWS CLI (opcional)
        try:
            subprocess.run(['aws', '--version'], check=True, capture_output=True)
            self.logger.info("âœ… AWS CLI encontrado")
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.logger.warning("âš ï¸ AWS CLI no encontrado (opcional)")
        
        self.logger.info("âœ… Prerequisites verificados")
        return True
    
    def install_dependencies(self) -> bool:
        """Instalar dependencias optimizadas para capa gratuita."""
        self.logger.info("ğŸ“¦ Instalando dependencias optimizadas...")
        
        # Dependencias mÃ­nimas para modo gratuito
        free_tier_requirements = [
            "streamlit>=1.28.0",
            "plotly>=5.17.0",
            "pandas>=2.0.0",
            "numpy>=1.24.0",
            "boto3>=1.29.0",
            "requests>=2.31.0",
            "python-dotenv>=1.0.0",
            "pyyaml>=6.0.0",
            "schedule>=1.2.0",  # Para tareas programadas
            "click>=8.1.0",     # Para CLI
        ]
        
        try:
            # Crear requirements_free_tier.txt
            requirements_file = self.project_root / "requirements_free_tier.txt"
            with open(requirements_file, 'w') as f:
                for req in free_tier_requirements:
                    f.write(f"{req}\n")
            
            # Instalar dependencias
            subprocess.run([
                sys.executable, '-m', 'pip', 'install', '-r', str(requirements_file)
            ], check=True)
            
            self.logger.info("âœ… Dependencias instaladas correctamente")
            return True
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"âŒ Error instalando dependencias: {e}")
            return False
    
    def create_config_files(self) -> bool:
        """Crear archivos de configuraciÃ³n optimizados."""
        self.logger.info("ğŸ“ Creando archivos de configuraciÃ³n...")
        
        try:
            # ConfiguraciÃ³n principal
            config = {
                "aws": {
                    "region": "us-east-1",
                    "free_tier_mode": True,
                    "cost_monitoring": True
                },
                "data_limits": {
                    "s3_max_gb": 4.5,  # Margen de seguridad
                    "athena_max_gb_monthly": 4.5,
                    "retention_days": 90,
                    "auto_cleanup": True
                },
                "dashboard": {
                    "type": "streamlit",
                    "port": 8501,
                    "auto_refresh_minutes": 30
                },
                "alerts": {
                    "email_enabled": False,
                    "slack_enabled": False,
                    "warning_threshold": 80,
                    "critical_threshold": 95
                }
            }
            
            config_file = self.project_root / "config" / "free_tier_config.json"
            config_file.parent.mkdir(exist_ok=True)
            
            with open(config_file, 'w') as f:
                json.dump(config, f, indent=2)
            
            # Archivo .env para variables de entorno
            env_file = self.project_root / ".env"
            env_content = """# Customer Satisfaction Analytics - Free Tier Configuration
                            AWS_DEFAULT_REGION=us-east-1
                            FREE_TIER_MODE=true
                            STREAMLIT_SERVER_PORT=8501
                            COST_MONITORING_ENABLED=true

                            # Opcional: Configurar para notificaciones
                            # SMTP_EMAIL=your-email@gmail.com
                            # SMTP_PASSWORD=your-app-password
                            # SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...

                            # LÃ­mites de seguridad
                            S3_MAX_SIZE_GB=4.5
                            ATHENA_MAX_SCAN_GB_MONTHLY=4.5
                            AUTO_CLEANUP_ENABLED=true
                            DATA_RETENTION_DAYS=90
                            """
            
            with open(env_file, 'w') as f:
                f.write(env_content)
            
            self.logger.info("âœ… Archivos de configuraciÃ³n creados")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Error creando configuraciÃ³n: {e}")
            return False
    
    def setup_streamlit_dashboard(self) -> bool:
        """Configurar dashboard Streamlit."""
        self.logger.info("ğŸ“Š Configurando dashboard Streamlit...")
        
        try:
            # Crear directorio de configuraciÃ³n Streamlit
            streamlit_dir = self.project_root / ".streamlit"
            streamlit_dir.mkdir(exist_ok=True)
            
            # ConfiguraciÃ³n Streamlit
            streamlit_config = """[global]
developmentMode = false

[server]
port = 8501
enableCORS = false
enableXsrfProtection = false

[browser]
gatherUsageStats = false

[theme]
primaryColor = "#1f77b4"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f8ff"
textColor = "#262730"
"""
            
            with open(streamlit_dir / "config.toml", 'w') as f:
                f.write(streamlit_config)
            
            # Script de inicio del dashboard
            start_script = self.project_root / "start_dashboard.py"
            script_content = '''#!/usr/bin/env python3
"""Script para iniciar el dashboard Streamlit."""

import subprocess
import sys
from pathlib import Path

def main():
    """Iniciar dashboard Streamlit."""
    dashboard_path = Path("analytics/streamlit_dashboard/app.py")
    
    if not dashboard_path.exists():
        print("âŒ Dashboard no encontrado en analytics/streamlit_dashboard/app.py")
        sys.exit(1)
    
    print("ğŸš€ Iniciando Customer Satisfaction Analytics Dashboard...")
    print("ğŸŒ El dashboard estarÃ¡ disponible en: http://localhost:8501")
    print("âŒ¨ï¸ Presiona Ctrl+C para detener")
    
    try:
        subprocess.run([
            sys.executable, "-m", "streamlit", "run", 
            str(dashboard_path),
            "--server.port", "8501",
            "--server.headless", "true"
        ])
    except KeyboardInterrupt:
        print("\\nğŸ‘‹ Dashboard detenido")

if __name__ == "__main__":
    main()
'''
            
            with open(start_script, 'w') as f:
                f.write(script_content)
            
            # Hacer ejecutable en sistemas Unix
            if os.name != 'nt':
                os.chmod(start_script, 0o755)
            
            self.logger.info("âœ… Dashboard Streamlit configurado")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Error configurando Streamlit: {e}")
            return False
    
    def setup_cost_monitoring(self) -> bool:
        """Configurar monitoreo automÃ¡tico de costos."""
        self.logger.info("ğŸ’° Configurando monitoreo de costos...")
        
        try:
            # Script de monitoreo diario
            monitor_script = self.project_root / "scripts" / "daily_cost_check.py"
            monitor_script.parent.mkdir(exist_ok=True)
            
            script_content = '''#!/usr/bin/env python3
"""Script de monitoreo diario de costos."""

import sys
import os
from pathlib import Path

# Agregar el directorio raÃ­z al path
sys.path.append(str(Path(__file__).parent.parent))

from scripts.aws_cost_monitor import AWSCostMonitor
import json
import logging

def main():
    """Ejecutar chequeo diario de costos."""
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸ” Ejecutando chequeo diario de costos...")
    
    try:
        # Configurar monitor
        monitor = AWSCostMonitor()
        
        # Ejecutar monitoreo con limpieza automÃ¡tica
        result = monitor.run_full_monitor(
            cleanup_old_data=True,
            notification_email=os.getenv('NOTIFICATION_EMAIL'),
            slack_webhook=os.getenv('SLACK_WEBHOOK_URL')
        )
        
        # Verificar alertas crÃ­ticas
        critical_alerts = [a for a in result['alerts'] if a['level'] == 'CRITICAL']
        
        if critical_alerts:
            logger.warning(f"ğŸš¨ {len(critical_alerts)} alertas crÃ­ticas encontradas")
            for alert in critical_alerts:
                logger.warning(f"  â€¢ {alert['service']}: {alert['message']}")
        else:
            logger.info("âœ… Todos los servicios dentro de lÃ­mites seguros")
        
        # Guardar estado
        status_file = Path("logs/daily_cost_status.json")
        status_file.parent.mkdir(exist_ok=True)
        
        with open(status_file, 'w') as f:
            json.dump({
                'timestamp': result.get('timestamp', ''),
                'total_cost': result['costs']['total_monthly_cost'],
                'alerts_count': len(result['alerts']),
                'critical_alerts_count': len(critical_alerts),
                'status': 'warning' if critical_alerts else 'ok'
            }, f, indent=2)
        
    except Exception as e:
        logger.error(f"âŒ Error en monitoreo: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
'''
            
            with open(monitor_script, 'w') as f:
                f.write(script_content)
            
            # Hacer ejecutable
            if os.name != 'nt':
                os.chmod(monitor_script, 0o755)
            
            # Crear tarea programada (cron job)
            cron_script = self.project_root / "setup_cron.sh"
            cron_content = f'''#!/bin/bash
# Configurar tarea diaria de monitoreo de costos

PYTHON_PATH="{sys.executable}"
SCRIPT_PATH="{monitor_script.absolute()}"
PROJECT_PATH="{self.project_root.absolute()}"

# Agregar al crontab (ejecutar diariamente a las 6:00 AM)
(crontab -l 2>/dev/null; echo "0 6 * * * cd $PROJECT_PATH && $PYTHON_PATH $SCRIPT_PATH >> logs/cost_monitor.log 2>&1") | crontab -

echo "âœ… Tarea programada configurada para monitoreo diario a las 6:00 AM"
echo "ğŸ“ Para ver tareas programadas: crontab -l"
echo "ğŸ“„ Logs en: logs/cost_monitor.log"
'''
            
            with open(cron_script, 'w') as f:
                f.write(cron_content)
            
            if os.name != 'nt':
                os.chmod(cron_script, 0o755)
            
            self.logger.info("âœ… Monitoreo de costos configurado")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Error configurando monitoreo: {e}")
            return False
    
    def create_optimization_scripts(self) -> bool:
        """Crear scripts de optimizaciÃ³n."""
        self.logger.info("âš¡ Creando scripts de optimizaciÃ³n...")
        
        try:
            # Script de optimizaciÃ³n de datos
            optimize_script = self.project_root / "scripts" / "optimize_data.py"
            script_content = '''#!/usr/bin/env python3
"""Script de optimizaciÃ³n de datos para capa gratuita."""

import boto3
import pandas as pd
import pyarrow.parquet as pq
import gzip
import json
from pathlib import Path
import logging

class DataOptimizer:
    """Optimizador de datos para reducir costos."""
    
    def __init__(self):
        self.s3 = boto3.client('s3')
        self.logger = logging.getLogger(__name__)
    
    def compress_csv_files(self, bucket_name: str, prefix: str = 'raw-data/'):
        """Comprimir archivos CSV en S3."""
        paginator = self.s3.get_paginator('list_objects_v2')
        
        for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):
            if 'Contents' not in page:
                continue
                
            for obj in page['Contents']:
                if obj['Key'].endswith('.csv') and not obj['Key'].endswith('.gz'):
                    self.logger.info(f"Comprimiendo {obj['Key']}...")
                    
                    # Descargar archivo
                    response = self.s3.get_object(Bucket=bucket_name, Key=obj['Key'])
                    data = response['Body'].read()
                    
                    # Comprimir
                    compressed_data = gzip.compress(data)
                    
                    # Subir archivo comprimido
                    new_key = obj['Key'] + '.gz'
                    self.s3.put_object(
                        Bucket=bucket_name,
                        Key=new_key,
                        Body=compressed_data,
                        ContentEncoding='gzip'
                    )
                    
                    # Eliminar archivo original
                    self.s3.delete_object(Bucket=bucket_name, Key=obj['Key'])
                    
                    savings = (1 - len(compressed_data) / len(data)) * 100
                    self.logger.info(f"  Ahorro: {savings:.1f}%")
    
    def convert_to_parquet(self, bucket_name: str, prefix: str = 'processed-data/'):
        """Convertir CSVs a Parquet comprimido."""
        # Esta funciÃ³n serÃ­a similar, convirtiendo CSVs a Parquet
        pass
    
    def cleanup_old_logs(self, retention_days: int = 30):
        """Limpiar logs antiguos localmente."""
        logs_dir = Path('logs')
        if not logs_dir.exists():
            return
        
        import time
        cutoff_time = time.time() - (retention_days * 24 * 3600)
        
        for log_file in logs_dir.glob('*.log'):
            if log_file.stat().st_mtime < cutoff_time:
                log_file.unlink()
                self.logger.info(f"Eliminado log antiguo: {log_file}")

def main():
    """Ejecutar optimizaciones."""
    optimizer = DataOptimizer()
    
    # AquÃ­ irÃ­a la lÃ³gica de optimizaciÃ³n
    print("ğŸ”§ Ejecutando optimizaciones...")
    print("âœ… Optimizaciones completadas")

if __name__ == "__main__":
    main()
'''
            
            with open(optimize_script, 'w') as f:
                f.write(script_content)
            
            self.logger.info("âœ… Scripts de optimizaciÃ³n creados")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Error creando scripts de optimizaciÃ³n: {e}")
            return False
    
    def setup_terraform_free_tier(self) -> bool:
        """Configurar Terraform para capa gratuita."""
        self.logger.info("ğŸ—ï¸ Configurando Terraform para capa gratuita...")
        
        try:
            # Crear variables optimizadas para free tier
            tfvars_file = self.project_root / "infra" / "terraform" / "free_tier.tfvars"
            
            tfvars_content = '''# ConfiguraciÃ³n optimizada para AWS Free Tier
project_name = "customer-satisfaction"
environment = "free-tier"
aws_region = "us-east-1"

# ConfiguraciÃ³n S3 optimizada
enable_versioning = false  # Reduce costos
enable_encryption = true
data_bucket_name = "customer-satisfaction-data-lake-free"

# ConfiguraciÃ³n Glue optimizada
crawler_schedule = "cron(0 6 ? * SUN *)"  # Solo domingos
glue_job_timeout = 60  # Timeout corto
glue_worker_type = "G.1X"  # Tipo mÃ¡s econÃ³mico
glue_number_of_workers = 2  # MÃ­nimo nÃºmero de workers

# ConfiguraciÃ³n Athena
athena_bytes_scanned_cutoff = 4000000000  # 4GB lÃ­mite

# Lifecycle polÃ­ticas agresivas
raw_data_transition_to_ia_days = 30
raw_data_transition_to_glacier_days = 60
processed_data_transition_to_ia_days = 90

# Logs con retenciÃ³n corta
logs_retention_days = 30

# Etiquetas para seguimiento de costos
additional_tags = {
  "CostCenter" = "free-tier"
  "Environment" = "development"
  "AutoShutdown" = "true"
}
'''
            
            with open(tfvars_file, 'w') as f:
                f.write(tfvars_content)
            
            # Script de despliegue para free tier
            deploy_script = self.project_root / "deploy_free_tier.sh"
            deploy_content = f'''#!/bin/bash
# Script de despliegue optimizado para AWS Free Tier

set -e

echo "ğŸš€ Desplegando Customer Satisfaction Analytics - Free Tier Mode"
echo "=================================================="

# Verificar AWS CLI
if ! command -v aws &> /dev/null; then
    echo "âŒ AWS CLI no encontrado. Por favor instalarlo primero."
    exit 1
fi

# Verificar credenciales AWS
if ! aws sts get-caller-identity &> /dev/null; then
    echo "âŒ Credenciales AWS no configuradas. Ejecutar: aws configure"
    exit 1
fi

cd infra/terraform

echo "ğŸ“‹ Inicializando Terraform..."
terraform init

echo "ğŸ“ Validando configuraciÃ³n..."
terraform validate

echo "ğŸ“Š Planificando despliegue (modo free tier)..."
terraform plan -var-file="free_tier.tfvars" -out=free_tier_plan.tfplan

echo ""
echo "âš ï¸  IMPORTANTE: Este despliegue estÃ¡ optimizado para AWS Free Tier"
echo "   â€¢ LÃ­mites automÃ¡ticos configurados"
echo "   â€¢ Lifecycle policies agresivas"
echo "   â€¢ Monitoreo de costos habilitado"
echo ""

read -p "Â¿Continuar con el despliegue? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ğŸ—ï¸ Desplegando infraestructura..."
    terraform apply free_tier_plan.tfplan
    
    echo ""
    echo "âœ… Despliegue completado!"
    echo "ğŸ“Š Configurar monitoreo de costos:"
    echo "   python scripts/aws_cost_monitor.py"
    echo ""
    echo "ğŸ¯ Iniciar dashboard:"
    echo "   python start_dashboard.py"
else
    echo "âŒ Despliegue cancelado"
    rm -f free_tier_plan.tfplan
fi
'''
            
            with open(deploy_script, 'w') as f:
                f.write(deploy_content)
            
            if os.name != 'nt':
                os.chmod(deploy_script, 0o755)
            
            self.logger.info("âœ… Terraform configurado para free tier")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Error configurando Terraform: {e}")
            return False
    
    def create_readme_free_tier(self) -> bool:
        """Crear README especÃ­fico para modo free tier."""
        self.logger.info("ğŸ“š Creando documentaciÃ³n free tier...")
        
        try:
            readme_content = '''# ğŸ†“ Customer Satisfaction Analytics - Free Tier Mode

## ğŸ¯ Modo Capa Gratuita Configurado

Este proyecto ha sido optimizado para funcionar completamente dentro de la **AWS Free Tier** durante los primeros 12 meses.

### âœ… ConfiguraciÃ³n Aplicada

- **Dashboard Streamlit** (Reemplaza QuickSight - Ahorro: $9/mes)
- **LÃ­mites automÃ¡ticos** en S3, Athena y Glue
- **Monitoreo de costos** automatizado
- **Limpieza automÃ¡tica** de datos antiguos
- **Alertas preventivas** antes de superar lÃ­mites

### ğŸš€ Inicio RÃ¡pido

```bash
# 1. Instalar dependencias
pip install -r requirements_free_tier.txt

# 2. Configurar AWS (si no estÃ¡ configurado)
aws configure

# 3. Desplegar infraestructura free tier
./deploy_free_tier.sh

# 4. Generar datos de prueba
python ingestion/scripts/data_simulator.py

# 5. Iniciar dashboard
python start_dashboard.py
```

### ğŸ“Š Dashboard

El dashboard estarÃ¡ disponible en: http://localhost:8501

**CaracterÃ­sticas:**
- ğŸ“ˆ KPIs en tiempo real
- ğŸ“Š GrÃ¡ficos interactivos
- ğŸ” Filtros dinÃ¡micos
- ğŸ’° Monitor de costos integrado
- ğŸ“± Responsive design

### ğŸ’° Monitoreo de Costos

El sistema monitorea automÃ¡ticamente:

```bash
# Chequeo manual
python scripts/aws_cost_monitor.py

# Configurar monitoreo diario
./setup_cron.sh  # Solo Linux/Mac
```

### ğŸš¨ LÃ­mites de Seguridad

| Servicio | LÃ­mite Free Tier | Configurado | Margen |
|----------|-----------------|-------------|--------|
| S3 Storage | 5 GB | 4.5 GB | 0.5 GB |
| Athena Scan | 5 GB/mes | 4.5 GB/mes | 0.5 GB |
| Glue DPU | 1M horas/mes | Uso mÃ­nimo | 999,990h |
| CloudWatch | 5 GB logs | Optimizado | Auto-cleanup |

### ğŸ› ï¸ Optimizaciones Aplicadas

1. **CompresiÃ³n automÃ¡tica** de datos
2. **Lifecycle policies** agresivas
3. **Particionado optimizado** para Athena
4. **Queries con LIMIT** automÃ¡tico
5. **Cache local** para reducir consultas

### ğŸ“‹ Comandos Ãštiles

```bash
# Ver uso actual
python scripts/aws_cost_monitor.py --quiet

# Limpiar datos antiguos
python scripts/optimize_data.py

# Verificar estado
cat logs/daily_cost_status.json

# Logs de monitoreo
tail -f logs/cost_monitor.log
```

### âš ï¸ Alertas Configuradas

- **80% uso**: Advertencia
- **95% uso**: CrÃ­tica + Limpieza automÃ¡tica
- **Notificaciones**: Email/Slack (opcional)

### ğŸ”§ Troubleshooting

**Problema**: "Cerca del lÃ­mite S3"
```bash
python scripts/optimize_data.py
```

**Problema**: "Athena escaneando mucho"
```bash
# Revisar queries en dashboard
# Agregar mÃ¡s LIMIT clauses
```

**Problema**: "Dashboard no inicia"
```bash
pip install streamlit
python -m streamlit run analytics/streamlit_dashboard/app.py
```

### ğŸ“ˆ DespuÃ©s de 12 Meses

Costo estimado post-free tier: **~$0.50/mes**

- S3: $0.01/mes (500MB)
- Athena: $0.005/mes (1GB)
- Glue: $0.02/mes (mÃ­nimo)
- CloudWatch: $0.01/mes

### ğŸ¯ PrÃ³ximos Pasos

1. Configurar notificaciones (email/Slack)
2. Personalizar dashboard segÃºn necesidades
3. Implementar modelos ML adicionales
4. Escalar gradualmente segÃºn requerimientos

---

ğŸš€ **Proyecto optimizado para $0/mes durante 12 meses!**
'''
            
            readme_file = self.project_root / "README_FREE_TIER.md"
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            
            self.logger.info("âœ… DocumentaciÃ³n free tier creada")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Error creando documentaciÃ³n: {e}")
            return False
    
    def run_setup(self, skip_dependencies: bool = False) -> bool:
        """Ejecutar setup completo."""
        self.logger.info("ğŸš€ Iniciando configuraciÃ³n Free Tier...")
        
        steps = [
            ("ğŸ” Verificar prerequisites", self.check_prerequisites),
            ("ğŸ“¦ Instalar dependencias", lambda: skip_dependencies or self.install_dependencies()),
            ("ğŸ“ Crear configuraciÃ³n", self.create_config_files),
            ("ğŸ“Š Configurar Streamlit", self.setup_streamlit_dashboard),
            ("ğŸ’° Configurar monitoreo", self.setup_cost_monitoring),
            ("âš¡ Crear optimizaciones", self.create_optimization_scripts),
            ("ğŸ—ï¸ Configurar Terraform", self.setup_terraform_free_tier),
            ("ğŸ“š Crear documentaciÃ³n", self.create_readme_free_tier),
        ]
        
        for step_name, step_func in steps:
            self.logger.info(f"{step_name}...")
            if not step_func():
                self.logger.error(f"âŒ FallÃ³: {step_name}")
                return False
            self.logger.info(f"âœ… Completado: {step_name}")
        
        self.logger.info("ğŸ‰ Setup Free Tier completado exitosamente!")
        return True
    
    def print_summary(self):
        """Imprimir resumen de configuraciÃ³n."""
        print("\n" + "="*60)
        print("ğŸ‰ CUSTOMER SATISFACTION ANALYTICS - FREE TIER CONFIGURADO")
        print("="*60)
        print()
        print("âœ… ConfiguraciÃ³n completada:")
        print("   â€¢ Dashboard Streamlit gratuito configurado")
        print("   â€¢ Monitoreo automÃ¡tico de costos habilitado")
        print("   â€¢ LÃ­mites de seguridad configurados")
        print("   â€¢ Scripts de optimizaciÃ³n creados")
        print("   â€¢ Terraform optimizado para free tier")
        print()
        print("ğŸš€ PrÃ³ximos pasos:")
        print("   1. Configurar AWS: aws configure")
        print("   2. Desplegar: ./deploy_free_tier.sh")
        print("   3. Generar datos: python ingestion/scripts/data_simulator.py")
        print("   4. Iniciar dashboard: python start_dashboard.py")
        print()
        print("ğŸ“Š Dashboard estarÃ¡ en: http://localhost:8501")
        print("ğŸ’° Costo estimado: $0/mes (primeros 12 meses)")
        print("ğŸ“š DocumentaciÃ³n: README_FREE_TIER.md")
        print()
        print("âš ï¸  IMPORTANTE: Revisa logs/cost_monitor.log regularmente")
        print("="*60)


def main():
    """FunciÃ³n principal."""
    parser = argparse.ArgumentParser(description='Setup Free Tier para Customer Satisfaction Analytics')
    parser.add_argument('--skip-deps', action='store_true', help='Saltar instalaciÃ³n de dependencias')
    parser.add_argument('--project-root', default='.', help='Directorio raÃ­z del proyecto')
    
    args = parser.parse_args()
    
    setup = FreeTierSetup(args.project_root)
    
    if setup.run_setup(skip_dependencies=args.skip_deps):
        setup.print_summary()
        return 0
    else:
        print("\nâŒ Setup fallÃ³. Revisa los logs para mÃ¡s detalles.")
        return 1


if __name__ == "__main__":
    sys.exit(main()) 