#!/usr/bin/env python3
"""
Setup autom√°tico para Customer Satisfaction Analytics - Modo Capa Gratuita
Script para configurar y optimizar el proyecto para mantenerse en AWS Free Tier.

Funciones:
- üîß Configuraci√≥n autom√°tica de l√≠mites
- üìä Instalaci√≥n del dashboard Streamlit gratuito
- ‚ö†Ô∏è Configuraci√≥n de alertas autom√°ticas
- üßπ Scripts de limpieza programada
- üí∞ Optimizaciones de costo
"""

import os
import sys
import subprocess
import json
import shutil
from pathlib import Path
import argparse
import logging
from datetime import datetime


class FreeTierSetup:
    """Configurador para modo capa gratuita."""
    
    def __init__(self, project_root: str = "."):
        """
        Inicializar configurador.
        
        Args:
            project_root: Directorio ra√≠z del proyecto
        """
        self.project_root = Path(project_root).absolute()
        self.setup_logging()
        
    def setup_logging(self):
        """Configurar logging."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def check_prerequisites(self) -> bool:
        """Verificar prerequisites del sistema."""
        self.logger.info("üîç Verificando prerequisites...")
        
        # Verificar Python
        if sys.version_info < (3, 8):
            self.logger.error("‚ùå Se requiere Python 3.8 o superior")
            return False
        
        # Verificar pip
        try:
            subprocess.run(['pip', '--version'], check=True, capture_output=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.logger.error("‚ùå pip no est√° instalado")
            return False
        
        # Verificar AWS CLI (opcional)
        try:
            subprocess.run(['aws', '--version'], check=True, capture_output=True)
            self.logger.info("‚úÖ AWS CLI encontrado")
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.logger.warning("‚ö†Ô∏è AWS CLI no encontrado (opcional)")
        
        self.logger.info("‚úÖ Prerequisites verificados")
        return True
    
    def install_dependencies(self) -> bool:
        """Instalar dependencias optimizadas para capa gratuita."""
        self.logger.info("üì¶ Instalando dependencias optimizadas...")
        
        # Dependencias m√≠nimas para modo gratuito
        free_tier_requirements = [
            "streamlit>=1.28.0",
            "plotly>=5.17.0",
            "pandas>=2.0.0",
            "numpy>=1.24.0",
            "boto3>=1.29.0",
            "requests>=2.31.0",
            "python-dotenv>=1.0.0",
            "pyyaml>=6.0.0",
            "schedule>=1.2.0",  # Para tareas programadas
            "click>=8.1.0",     # Para CLI
        ]
        
        try:
            # Crear requirements_free_tier.txt
            requirements_file = self.project_root / "requirements_free_tier.txt"
            with open(requirements_file, 'w') as f:
                for req in free_tier_requirements:
                    f.write(f"{req}\n")
            
            # Instalar dependencias
            subprocess.run([
                sys.executable, '-m', 'pip', 'install', '-r', str(requirements_file)
            ], check=True)
            
            self.logger.info("‚úÖ Dependencias instaladas correctamente")
            return True
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"‚ùå Error instalando dependencias: {e}")
            return False
    
    def create_config_files(self) -> bool:
        """Crear archivos de configuraci√≥n optimizados."""
        self.logger.info("üìù Creando archivos de configuraci√≥n...")
        
        try:
            # Configuraci√≥n principal
            config = {
                "aws": {
                    "region": "us-east-1",
                    "free_tier_mode": True,
                    "cost_monitoring": True
                },
                "data_limits": {
                    "s3_max_gb": 4.5,  # Margen de seguridad
                    "athena_max_gb_monthly": 4.5,
                    "retention_days": 90,
                    "auto_cleanup": True
                },
                "dashboard": {
                    "type": "streamlit",
                    "port": 8501,
                    "auto_refresh_minutes": 30
                },
                "alerts": {
                    "email_enabled": False,
                    "slack_enabled": False,
                    "warning_threshold": 80,
                    "critical_threshold": 95
                }
            }
            
            config_file = self.project_root / "config" / "free_tier_config.json"
            config_file.parent.mkdir(exist_ok=True)
            
            with open(config_file, 'w') as f:
                json.dump(config, f, indent=2)
            
            # Archivo .env para variables de entorno
            env_file = self.project_root / ".env"
            env_content = """# Customer Satisfaction Analytics - Free Tier Configuration
                            AWS_DEFAULT_REGION=us-east-1
                            FREE_TIER_MODE=true
                            STREAMLIT_SERVER_PORT=8501
                            COST_MONITORING_ENABLED=true

                            # Opcional: Configurar para notificaciones
                            # SMTP_EMAIL=your-email@gmail.com
                            # SMTP_PASSWORD=your-app-password
                            # SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...

                            # L√≠mites de seguridad
                            S3_MAX_SIZE_GB=4.5
                            ATHENA_MAX_SCAN_GB_MONTHLY=4.5
                            AUTO_CLEANUP_ENABLED=true
                            DATA_RETENTION_DAYS=90
                            """
            
            with open(env_file, 'w') as f:
                f.write(env_content)
            
            self.logger.info("‚úÖ Archivos de configuraci√≥n creados")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error creando configuraci√≥n: {e}")
            return False
    
    def setup_streamlit_dashboard(self) -> bool:
        """Configurar dashboard Streamlit."""
        self.logger.info("üìä Configurando dashboard Streamlit...")
        
        try:
            # Crear directorio de configuraci√≥n Streamlit
            streamlit_dir = self.project_root / ".streamlit"
            streamlit_dir.mkdir(exist_ok=True)
            
            # Configuraci√≥n Streamlit
            streamlit_config = """[global]
developmentMode = false

[server]
port = 8501
enableCORS = false
enableXsrfProtection = false

[browser]
gatherUsageStats = false

[theme]
primaryColor = "#1f77b4"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f8ff"
textColor = "#262730"
"""
            
            with open(streamlit_dir / "config.toml", 'w') as f:
                f.write(streamlit_config)
            
            # Script de inicio del dashboard
            start_script = self.project_root / "start_dashboard.py"
            script_content = '''#!/usr/bin/env python3
"""Script para iniciar el dashboard Streamlit."""

import subprocess
import sys
from pathlib import Path

def main():
    """Iniciar dashboard Streamlit."""
    dashboard_path = Path("analytics/streamlit_dashboard/app.py")
    
    if not dashboard_path.exists():
        print("‚ùå Dashboard no encontrado en analytics/streamlit_dashboard/app.py")
        sys.exit(1)
    
    print("üöÄ Iniciando Customer Satisfaction Analytics Dashboard...")
    print("üåê El dashboard estar√° disponible en: http://localhost:8501")
    print("‚å®Ô∏è Presiona Ctrl+C para detener")
    
    try:
        subprocess.run([
            sys.executable, "-m", "streamlit", "run", 
            str(dashboard_path),
            "--server.port", "8501",
            "--server.headless", "true"
        ])
    except KeyboardInterrupt:
        print("\\nüëã Dashboard detenido")

if __name__ == "__main__":
    main()
'''
            
            with open(start_script, 'w') as f:
                f.write(script_content)
            
            # Hacer ejecutable en sistemas Unix
            if os.name != 'nt':
                os.chmod(start_script, 0o755)
            
            self.logger.info("‚úÖ Dashboard Streamlit configurado")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error configurando Streamlit: {e}")
            return False
    
    def setup_cost_monitoring(self) -> bool:
        """Configurar monitoreo autom√°tico de costos."""
        self.logger.info("üí∞ Configurando monitoreo de costos...")
        
        try:
            # Script de monitoreo diario
            monitor_script = self.project_root / "scripts" / "daily_cost_check.py"
            monitor_script.parent.mkdir(exist_ok=True)
            
            script_content = '''#!/usr/bin/env python3
"""Script de monitoreo diario de costos."""

import sys
import os
from pathlib import Path

# Agregar el directorio ra√≠z al path
sys.path.append(str(Path(__file__).parent.parent))

from scripts.aws_cost_monitor import AWSCostMonitor
import json
import logging

def main():
    """Ejecutar chequeo diario de costos."""
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    logger.info("üîç Ejecutando chequeo diario de costos...")
    
    try:
        # Configurar monitor
        monitor = AWSCostMonitor()
        
        # Ejecutar monitoreo con limpieza autom√°tica
        result = monitor.run_full_monitor(
            cleanup_old_data=True,
            notification_email=os.getenv('NOTIFICATION_EMAIL'),
            slack_webhook=os.getenv('SLACK_WEBHOOK_URL')
        )
        
        # Verificar alertas cr√≠ticas
        critical_alerts = [a for a in result['alerts'] if a['level'] == 'CRITICAL']
        
        if critical_alerts:
            logger.warning(f"üö® {len(critical_alerts)} alertas cr√≠ticas encontradas")
            for alert in critical_alerts:
                logger.warning(f"  ‚Ä¢ {alert['service']}: {alert['message']}")
        else:
            logger.info("‚úÖ Todos los servicios dentro de l√≠mites seguros")
        
        # Guardar estado
        status_file = Path("logs/daily_cost_status.json")
        status_file.parent.mkdir(exist_ok=True)
        
        with open(status_file, 'w') as f:
            json.dump({
                'timestamp': result.get('timestamp', ''),
                'total_cost': result['costs']['total_monthly_cost'],
                'alerts_count': len(result['alerts']),
                'critical_alerts_count': len(critical_alerts),
                'status': 'warning' if critical_alerts else 'ok'
            }, f, indent=2)
        
    except Exception as e:
        logger.error(f"‚ùå Error en monitoreo: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
'''
            
            with open(monitor_script, 'w') as f:
                f.write(script_content)
            
            # Hacer ejecutable
            if os.name != 'nt':
                os.chmod(monitor_script, 0o755)
            
            # Crear tarea programada (cron job)
            cron_script = self.project_root / "setup_cron.sh"
            cron_content = f'''#!/bin/bash
# Configurar tarea diaria de monitoreo de costos

PYTHON_PATH="{sys.executable}"
SCRIPT_PATH="{monitor_script.absolute()}"
PROJECT_PATH="{self.project_root.absolute()}"

# Agregar al crontab (ejecutar diariamente a las 6:00 AM)
(crontab -l 2>/dev/null; echo "0 6 * * * cd $PROJECT_PATH && $PYTHON_PATH $SCRIPT_PATH >> logs/cost_monitor.log 2>&1") | crontab -

echo "‚úÖ Tarea programada configurada para monitoreo diario a las 6:00 AM"
echo "üìù Para ver tareas programadas: crontab -l"
echo "üìÑ Logs en: logs/cost_monitor.log"
'''
            
            with open(cron_script, 'w') as f:
                f.write(cron_content)
            
            if os.name != 'nt':
                os.chmod(cron_script, 0o755)
            
            self.logger.info("‚úÖ Monitoreo de costos configurado")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error configurando monitoreo: {e}")
            return False
    
    def create_optimization_scripts(self) -> bool:
        """Crear scripts de optimizaci√≥n."""
        self.logger.info("‚ö° Creando scripts de optimizaci√≥n...")
        
        try:
            # Script de optimizaci√≥n de datos
            optimize_script = self.project_root / "scripts" / "optimize_data.py"
            script_content = '''#!/usr/bin/env python3
"""Script de optimizaci√≥n de datos para capa gratuita."""

import boto3
import pandas as pd
import pyarrow.parquet as pq
import gzip
import json
from pathlib import Path
import logging

class DataOptimizer:
    """Optimizador de datos para reducir costos."""
    
    def __init__(self):
        self.s3 = boto3.client('s3')
        self.logger = logging.getLogger(__name__)
    
    def compress_csv_files(self, bucket_name: str, prefix: str = 'raw-data/'):
        """Comprimir archivos CSV en S3."""
        paginator = self.s3.get_paginator('list_objects_v2')
        
        for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):
            if 'Contents' not in page:
                continue
                
            for obj in page['Contents']:
                if obj['Key'].endswith('.csv') and not obj['Key'].endswith('.gz'):
                    self.logger.info(f"Comprimiendo {obj['Key']}...")
                    
                    # Descargar archivo
                    response = self.s3.get_object(Bucket=bucket_name, Key=obj['Key'])
                    data = response['Body'].read()
                    
                    # Comprimir
                    compressed_data = gzip.compress(data)
                    
                    # Subir archivo comprimido
                    new_key = obj['Key'] + '.gz'
                    self.s3.put_object(
                        Bucket=bucket_name,
                        Key=new_key,
                        Body=compressed_data,
                        ContentEncoding='gzip'
                    )
                    
                    # Eliminar archivo original
                    self.s3.delete_object(Bucket=bucket_name, Key=obj['Key'])
                    
                    savings = (1 - len(compressed_data) / len(data)) * 100
                    self.logger.info(f"  Ahorro: {savings:.1f}%")
    
    def convert_to_parquet(self, bucket_name: str, prefix: str = 'processed-data/'):
        """Convertir CSVs a Parquet comprimido."""
        # Esta funci√≥n ser√≠a similar, convirtiendo CSVs a Parquet
        pass
    
    def cleanup_old_logs(self, retention_days: int = 30):
        """Limpiar logs antiguos localmente."""
        logs_dir = Path('logs')
        if not logs_dir.exists():
            return
        
        import time
        cutoff_time = time.time() - (retention_days * 24 * 3600)
        
        for log_file in logs_dir.glob('*.log'):
            if log_file.stat().st_mtime < cutoff_time:
                log_file.unlink()
                self.logger.info(f"Eliminado log antiguo: {log_file}")

def main():
    """Ejecutar optimizaciones."""
    optimizer = DataOptimizer()
    
    # Aqu√≠ ir√≠a la l√≥gica de optimizaci√≥n
    print("üîß Ejecutando optimizaciones...")
    print("‚úÖ Optimizaciones completadas")

if __name__ == "__main__":
    main()
'''
            
            with open(optimize_script, 'w') as f:
                f.write(script_content)
            
            self.logger.info("‚úÖ Scripts de optimizaci√≥n creados")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error creando scripts de optimizaci√≥n: {e}")
            return False
    
    def setup_terraform_free_tier(self) -> bool:
        """Configurar Terraform para capa gratuita."""
        self.logger.info("üèóÔ∏è Configurando Terraform para capa gratuita...")
        
        try:
            # Crear variables optimizadas para free tier
            tfvars_file = self.project_root / "infra" / "terraform" / "free_tier.tfvars"
            
            tfvars_content = '''# Configuraci√≥n optimizada para AWS Free Tier
project_name = "customer-satisfaction"
environment = "free-tier"
aws_region = "us-east-1"

# Configuraci√≥n S3 optimizada
enable_versioning = false  # Reduce costos
enable_encryption = true
data_bucket_name = "customer-satisfaction-data-lake-free"

# Configuraci√≥n Glue optimizada
crawler_schedule = "cron(0 6 ? * SUN *)"  # Solo domingos
glue_job_timeout = 60  # Timeout corto
glue_worker_type = "G.1X"  # Tipo m√°s econ√≥mico
glue_number_of_workers = 2  # M√≠nimo n√∫mero de workers

# Configuraci√≥n Athena
athena_bytes_scanned_cutoff = 4000000000  # 4GB l√≠mite

# Lifecycle pol√≠ticas agresivas
raw_data_transition_to_ia_days = 30
raw_data_transition_to_glacier_days = 60
processed_data_transition_to_ia_days = 90

# Logs con retenci√≥n corta
logs_retention_days = 30

# Etiquetas para seguimiento de costos
additional_tags = {
  "CostCenter" = "free-tier"
  "Environment" = "development"
  "AutoShutdown" = "true"
}
'''
            
            with open(tfvars_file, 'w') as f:
                f.write(tfvars_content)
            
            # Script de despliegue para free tier
            deploy_script = self.project_root / "deploy_free_tier.sh"
            deploy_content = f'''#!/bin/bash
# Script de despliegue optimizado para AWS Free Tier

set -e

echo "üöÄ Desplegando Customer Satisfaction Analytics - Free Tier Mode"
echo "=================================================="

# Verificar AWS CLI
if ! command -v aws &> /dev/null; then
    echo "‚ùå AWS CLI no encontrado. Por favor instalarlo primero."
    exit 1
fi

# Verificar credenciales AWS
if ! aws sts get-caller-identity &> /dev/null; then
    echo "‚ùå Credenciales AWS no configuradas. Ejecutar: aws configure"
    exit 1
fi

cd infra/terraform

echo "üìã Inicializando Terraform..."
terraform init

echo "üìù Validando configuraci√≥n..."
terraform validate

echo "üìä Planificando despliegue (modo free tier)..."
terraform plan -var-file="free_tier.tfvars" -out=free_tier_plan.tfplan

echo ""
echo "‚ö†Ô∏è  IMPORTANTE: Este despliegue est√° optimizado para AWS Free Tier"
echo "   ‚Ä¢ L√≠mites autom√°ticos configurados"
echo "   ‚Ä¢ Lifecycle policies agresivas"
echo "   ‚Ä¢ Monitoreo de costos habilitado"
echo ""

read -p "¬øContinuar con el despliegue? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "üèóÔ∏è Desplegando infraestructura..."
    terraform apply free_tier_plan.tfplan
    
    echo ""
    echo "‚úÖ Despliegue completado!"
    echo "üìä Configurar monitoreo de costos:"
    echo "   python scripts/aws_cost_monitor.py"
    echo ""
    echo "üéØ Iniciar dashboard:"
    echo "   python start_dashboard.py"
else
    echo "‚ùå Despliegue cancelado"
    rm -f free_tier_plan.tfplan
fi
'''
            
            with open(deploy_script, 'w') as f:
                f.write(deploy_content)
            
            if os.name != 'nt':
                os.chmod(deploy_script, 0o755)
            
            self.logger.info("‚úÖ Terraform configurado para free tier")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error configurando Terraform: {e}")
            return False
    
    def create_readme_free_tier(self) -> bool:
        """Crear README espec√≠fico para modo free tier."""
        self.logger.info("üìö Creando documentaci√≥n free tier...")
        
        try:
            readme_content = '''# üÜì Customer Satisfaction Analytics - Free Tier Mode

## üéØ Modo Capa Gratuita Configurado

Este proyecto ha sido optimizado para funcionar completamente dentro de la **AWS Free Tier** durante los primeros 12 meses.

### ‚úÖ Configuraci√≥n Aplicada

- **Dashboard Streamlit** (Reemplaza QuickSight - Ahorro: $9/mes)
- **L√≠mites autom√°ticos** en S3, Athena y Glue
- **Monitoreo de costos** automatizado
- **Limpieza autom√°tica** de datos antiguos
- **Alertas preventivas** antes de superar l√≠mites

### üöÄ Inicio R√°pido

```bash
# 1. Instalar dependencias
pip install -r requirements_free_tier.txt

# 2. Configurar AWS (si no est√° configurado)
aws configure

# 3. Desplegar infraestructura free tier
./deploy_free_tier.sh

# 4. Generar datos de prueba
python ingestion/scripts/data_simulator.py

# 5. Iniciar dashboard
python start_dashboard.py
```

### üìä Dashboard

El dashboard estar√° disponible en: http://localhost:8501

**Caracter√≠sticas:**
- üìà KPIs en tiempo real
- üìä Gr√°ficos interactivos
- üîç Filtros din√°micos
- üí∞ Monitor de costos integrado
- üì± Responsive design

### üí∞ Monitoreo de Costos

El sistema monitorea autom√°ticamente:

```bash
# Chequeo manual
python scripts/aws_cost_monitor.py

# Configurar monitoreo diario
./setup_cron.sh  # Solo Linux/Mac
```

### üö® L√≠mites de Seguridad

| Servicio | L√≠mite Free Tier | Configurado | Margen |
|----------|-----------------|-------------|--------|
| S3 Storage | 5 GB | 4.5 GB | 0.5 GB |
| Athena Scan | 5 GB/mes | 4.5 GB/mes | 0.5 GB |
| Glue DPU | 1M horas/mes | Uso m√≠nimo | 999,990h |
| CloudWatch | 5 GB logs | Optimizado | Auto-cleanup |

### üõ†Ô∏è Optimizaciones Aplicadas

1. **Compresi√≥n autom√°tica** de datos
2. **Lifecycle policies** agresivas
3. **Particionado optimizado** para Athena
4. **Queries con LIMIT** autom√°tico
5. **Cache local** para reducir consultas

### üìã Comandos √ötiles

```bash
# Ver uso actual
python scripts/aws_cost_monitor.py --quiet

# Limpiar datos antiguos
python scripts/optimize_data.py

# Verificar estado
cat logs/daily_cost_status.json

# Logs de monitoreo
tail -f logs/cost_monitor.log
```

### ‚ö†Ô∏è Alertas Configuradas

- **80% uso**: Advertencia
- **95% uso**: Cr√≠tica + Limpieza autom√°tica
- **Notificaciones**: Email/Slack (opcional)

### üîß Troubleshooting

**Problema**: "Cerca del l√≠mite S3"
```bash
python scripts/optimize_data.py
```

**Problema**: "Athena escaneando mucho"
```bash
# Revisar queries en dashboard
# Agregar m√°s LIMIT clauses
```

**Problema**: "Dashboard no inicia"
```bash
pip install streamlit
python -m streamlit run analytics/streamlit_dashboard/app.py
```

### üìà Despu√©s de 12 Meses

Costo estimado post-free tier: **~$0.50/mes**

- S3: $0.01/mes (500MB)
- Athena: $0.005/mes (1GB)
- Glue: $0.02/mes (m√≠nimo)
- CloudWatch: $0.01/mes

### üéØ Pr√≥ximos Pasos

1. Configurar notificaciones (email/Slack)
2. Personalizar dashboard seg√∫n necesidades
3. Implementar modelos ML adicionales
4. Escalar gradualmente seg√∫n requerimientos

---

üöÄ **Proyecto optimizado para $0/mes durante 12 meses!**
'''
            
            readme_file = self.project_root / "README_FREE_TIER.md"
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            
            self.logger.info("‚úÖ Documentaci√≥n free tier creada")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error creando documentaci√≥n: {e}")
            return False
    
    def run_setup(self, skip_dependencies: bool = False) -> bool:
        """Ejecutar setup completo."""
        self.logger.info("üöÄ Iniciando configuraci√≥n Free Tier...")
        
        steps = [
            ("üîç Verificar prerequisites", self.check_prerequisites),
            ("üì¶ Instalar dependencias", lambda: skip_dependencies or self.install_dependencies()),
            ("üìù Crear configuraci√≥n", self.create_config_files),
            ("üìä Configurar Streamlit", self.setup_streamlit_dashboard),
            ("üí∞ Configurar monitoreo", self.setup_cost_monitoring),
            ("‚ö° Crear optimizaciones", self.create_optimization_scripts),
            ("üèóÔ∏è Configurar Terraform", self.setup_terraform_free_tier),
            ("üìö Crear documentaci√≥n", self.create_readme_free_tier),
        ]
        
        for step_name, step_func in steps:
            self.logger.info(f"{step_name}...")
            if not step_func():
                self.logger.error(f"‚ùå Fall√≥: {step_name}")
                return False
            self.logger.info(f"‚úÖ Completado: {step_name}")
        
        self.logger.info("üéâ Setup Free Tier completado exitosamente!")
        return True
    
    def print_summary(self):
        """Imprimir resumen de configuraci√≥n."""
        print("\n" + "="*60)
        print("üéâ CUSTOMER SATISFACTION ANALYTICS - FREE TIER CONFIGURADO")
        print("="*60)
        print()
        print("‚úÖ Configuraci√≥n completada:")
        print("   ‚Ä¢ Dashboard Streamlit gratuito configurado")
        print("   ‚Ä¢ Monitoreo autom√°tico de costos habilitado")
        print("   ‚Ä¢ L√≠mites de seguridad configurados")
        print("   ‚Ä¢ Scripts de optimizaci√≥n creados")
        print("   ‚Ä¢ Terraform optimizado para free tier")
        print()
        print("üöÄ Pr√≥ximos pasos:")
        print("   1. Configurar AWS: aws configure")
        print("   2. Desplegar: ./deploy_free_tier.sh")
        print("   3. Generar datos: python ingestion/scripts/data_simulator.py")
        print("   4. Iniciar dashboard: python start_dashboard.py")
        print()
        print("üìä Dashboard estar√° en: http://localhost:8501")
        print("üí∞ Costo estimado: $0/mes (primeros 12 meses)")
        print("üìö Documentaci√≥n: README_FREE_TIER.md")
        print()
        print("‚ö†Ô∏è  IMPORTANTE: Revisa logs/cost_monitor.log regularmente")
        print("="*60)


def main():
    """Funci√≥n principal."""
    parser = argparse.ArgumentParser(description='Setup Free Tier para Customer Satisfaction Analytics')
    parser.add_argument('--skip-deps', action='store_true', help='Saltar instalaci√≥n de dependencias')
    parser.add_argument('--project-root', default='.', help='Directorio ra√≠z del proyecto')
    
    args = parser.parse_args()
    
    setup = FreeTierSetup(args.project_root)
    
    if setup.run_setup(skip_dependencies=args.skip_deps):
        setup.print_summary()
        return 0
    else:
        print("\n‚ùå Setup fall√≥. Revisa los logs para m√°s detalles.")
        return 1


if __name__ == "__main__":
    sys.exit(main()) 